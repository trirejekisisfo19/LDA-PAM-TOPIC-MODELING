{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMW7tDcuUvLbEN2mWxTU8Hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install tomotopy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oRqCHk3AM3kl","executionInfo":{"status":"ok","timestamp":1688910393846,"user_tz":-420,"elapsed":4880,"user":{"displayName":"Tri Rejeki","userId":"03000653045569033643"}},"outputId":"2d69fec4-39f7-4e6d-ea96-2fe97810e3f0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tomotopy\n","  Downloading tomotopy-0.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tomotopy) (1.22.4)\n","Installing collected packages: tomotopy\n","Successfully installed tomotopy-0.12.4\n"]}]},{"cell_type":"code","source":["import tomotopy as tp\n","import pandas as pd\n","import numpy as np\n","import csv\n","from sklearn.model_selection import GridSearchCV, ParameterGrid\n","from sklearn.base import BaseEstimator\n","from IPython.display import clear_output\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3y1kxapLddC","executionInfo":{"status":"ok","timestamp":1688910413109,"user_tz":-420,"elapsed":19273,"user":{"displayName":"Tri Rejeki","userId":"03000653045569033643"}},"outputId":"cfc83b98-3949-4520-c68b-282ac8171948"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import ast\n","data_clean = pd.read_csv('/content/drive/MyDrive/Bahan Penelitian/dataset penelitian/data_bersih.csv')\n","data_clean['isi_stemmed'] = data_clean['isi_stemmed'].apply(ast.literal_eval)\n","\n","corpus = tp.utils.Corpus()\n","for doc in data_clean['isi_stemmed']:\n","    if doc:\n","        corpus.add_doc(doc)"],"metadata":{"id":"IIA2emtcThWW","executionInfo":{"status":"ok","timestamp":1688910416178,"user_tz":-420,"elapsed":3076,"user":{"displayName":"Tri Rejeki","userId":"03000653045569033643"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class TopicWrapper(BaseEstimator):\n","    def __init__(self, k1:int, k2:int, top_n:int=25, train_iter:int=500,\n","                 random_state:int=42, num_workers:int=1) -> None:\n","        super().__init__()\n","        self.random_state = random_state\n","        self.k1 = k1\n","        self.k2 = k2\n","        self.train_iter = train_iter\n","        self.top_n = top_n\n","        self.num_workers = num_workers\n","        self.model = None\n","\n","    def __init_model__(self):\n","        return tp.PAModel(tw=tp.TermWeight.PMI, min_cf=10,\n","                          k1=self.k1, k2=self.k2, seed=self.random_state)\n","\n","    def fit(self, X, **kwargs):\n","        corpus = tp.utils.Corpus()\n","        for doc in X:\n","            if doc:\n","                corpus.add_doc(doc)\n","        self.model = self.__init_model__()\n","        self.model.add_corpus(corpus)\n","        self.model.burn_in = 100\n","        self.model.train(self.train_iter, workers=self.num_workers)\n","        return self\n","\n","    def predict(self, X):\n","        infered_corpus, ll = self.model.infer(X)\n","        return infered_corpus, ll\n","\n","    def score(self, *args, **kwargs) -> float:\n","        return tp.coherence.Coherence(self.model, coherence=\"c_v\").get_score()\n","\n","    def set_params(self, **params):\n","        self.model = None\n","        return super().set_params(**params)"],"metadata":{"id":"E2vvLs8YK4Qm","executionInfo":{"status":"ok","timestamp":1688910416180,"user_tz":-420,"elapsed":18,"user":{"displayName":"Tri Rejeki","userId":"03000653045569033643"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["model = TopicWrapper(k1=1, k2=1, top_n=50, num_workers=1, train_iter=500, random_state=42)\n","param_grid = []\n","\n","for i in range(1, 5):\n","    for j in range(i, 20):\n","        param_grid.append({\"k1\": [i], \"k2\": [j]})\n","\n","search = GridSearchCV(model, param_grid,cv=4, verbose=2)\n","result = search.fit(corpus)\n","clear_output()\n","print(\"Best Params :\")\n","print(result.best_params_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1lywKaWODXbl","executionInfo":{"status":"ok","timestamp":1688724871697,"user_tz":-420,"elapsed":29361377,"user":{"displayName":"Tri Rejeki","userId":"03000653045569033643"}},"outputId":"a480569b-0f14-453c-fd12-daa5dceac544"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Params :\n","{'k1': 3, 'k2': 16}\n"]}]},{"cell_type":"code","source":["# Set the best model\n","best_k1 = 3\n","best_k2 = 16\n","\n","model = tp.PAModel(tw=tp.TermWeight.PMI, min_cf=10,\n","                   k1=best_k1,  k2= best_k2, corpus=corpus, seed=42)\n","model.burn_in = 100\n","model.train(1000, workers=1)\n"],"metadata":{"id":"PNtIOLN7pCSc","executionInfo":{"status":"ok","timestamp":1688910658123,"user_tz":-420,"elapsed":236659,"user":{"displayName":"Tri Rejeki","userId":"03000653045569033643"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model.k2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ygw7c42sQRb","executionInfo":{"status":"ok","timestamp":1688822905858,"user_tz":-420,"elapsed":13,"user":{"displayName":"Tri Rejeki","userId":"03000653045569033643"}},"outputId":"8db157ed-4b83-4246-a498-b8f7c69354b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# get sub topics\n","top_n = 3\n","for k in range(best_k1):\n","    print(\"SUPER TOPIC\", k)\n","    print(\"sub topic:\")\n","    print([item[0] for item in model.get_sub_topics(k,top_n=top_n)])\n","    print(\"==========================\")\n","\n","# Terdapat 3 super topik dengan masing masing penyusun sub topic itu. contoh super topik 1 terdiri dari sub topik [14,15,6]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M31BslHVjlT1","executionInfo":{"status":"ok","timestamp":1688914879677,"user_tz":-420,"elapsed":785,"user":{"displayName":"Tri Rejeki","userId":"03000653045569033643"}},"outputId":"c4d1e898-e996-4b0a-f643-0ed9cafeae9f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["SUPER TOPIC 0\n","sub topic:\n","[14, 15, 6]\n","==========================\n","SUPER TOPIC 1\n","sub topic:\n","[15, 6, 0]\n","==========================\n","SUPER TOPIC 2\n","sub topic:\n","[15, 14, 0]\n","==========================\n"]}]},{"cell_type":"code","source":["for k in range(best_k1):\n","  print([item for item in model.get_sub_topic_dist(k,normalize=True)])"],"metadata":{"id":"gG4UegeDiSDV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get topic words\n","top_n = 10\n","for k in range(best_k2):\n","    print(\"TOPIC\", k)\n","    print(\"Words:\")\n","    print([item[0] for item in model.get_topic_words(k, top_n=top_n)])\n","    print(\"==========================\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o-DHxTT9pesr","executionInfo":{"status":"ok","timestamp":1688911474799,"user_tz":-420,"elapsed":389,"user":{"displayName":"Tri Rejeki","userId":"03000653045569033643"}},"outputId":"3dc542ed-fd72-4e3c-b129-4e55a04547a1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["TOPIC 0\n","Words:\n","['bantu', 'ganjar', 'jateng', 'desa', 'tani', 'banjir', 'rumah', 'kabupaten', 'program', 'nelayan']\n","==========================\n","TOPIC 1\n","Words:\n","['jakarta', 'piala dunia', 'heru budi', 'fifa', 'dki jakarta', 'heru', 'israel', 'gubernur', 'gubernur dki', 'tuan rumah']\n","==========================\n","TOPIC 2\n","Words:\n","['pemilu', 'kpu', 'bawaslu', 'gugat', 'kampanye', 'partai', 'putus', 'partai ummat', 'serta milu', 'atur']\n","==========================\n","TOPIC 3\n","Words:\n","['giat', 'ganjar', 'masyarakat', 'latih', 'milenial', 'srikandi ganjar', 'ganjar pranowo', 'pemuda', 'perempuan', 'budaya']\n","==========================\n","TOPIC 4\n","Words:\n","['jatim', 'nu', 'khofifah', 'surabaya', 'jalan', 'prabowo', 'kiai', 'rp', 'ulama', 'jawa timur']\n","==========================\n","TOPIC 5\n","Words:\n","['aceh', 'spanduk', 'baliho', 'sepeda', 'pasang', 'anies', 'transjakarta', 'halte', 'jalan', 'sopir truk']\n","==========================\n","TOPIC 6\n","Words:\n","['gerindra', 'ppp', 'kib', 'pkb', 'golkar', 'prabowo', 'sandiaga', 'koalisi', 'imin', 'partai gerindra']\n","==========================\n","TOPIC 7\n","Words:\n","['pdip', 'jokowi', 'ganjar', 'hasto', 'rawan', 'megawati', 'dukung', 'pdi juang', 'rudy', 'puan']\n","==========================\n","TOPIC 8\n","Words:\n","['prabowo', 'tni', 'menteri tahan', 'deddy', 'jokowi', 'pesawat', 'trump', 'medan', 'bobby', 'biden']\n","==========================\n","TOPIC 9\n","Words:\n","['survei', 'persen', 'elektabilitas', 'pilih', 'musra', 'responden', 'prabowo', 'hasil survei', 'prabowo subianto', 'nama']\n","==========================\n","TOPIC 10\n","Words:\n","['kpk', 'rambut putih', 'formula', 'wajah', 'kerut', 'rambut', 'korban', 'jokowi', 'pimpin', 'yusril']\n","==========================\n","TOPIC 11\n","Words:\n","['ridwan kamil', 'santri', 'emil', 'doa', 'masjid', 'ganjar', 'pesantren', 'jabar', 'ponpes', 'jawa barat']\n","==========================\n","TOPIC 12\n","Words:\n","['gibran', 'solo', 'anies', 'foto', 'hadir', 'temu', 'acara', 'wali kota', 'ganjar', 'solo gibran']\n","==========================\n","TOPIC 13\n","Words:\n","['jokowi', 'menteri', 'pan', 'nasdem', 'temu', 'presiden', 'perintah', 'reshuffle', 'kabinet', 'istana']\n","==========================\n","TOPIC 14\n","Words:\n","['indonesia', 'politik', 'bangsa', 'negara', 'pimpin', 'rakyat', 'satu', 'didik', 'dunia', 'demokrasi']\n","==========================\n","TOPIC 15\n","Words:\n","['nasdem', 'anies', 'pks', 'partai', 'ahy', 'demokrat', 'deklarasi', 'anies baswedan', 'koalisi', 'partai demokrat']\n","==========================\n"]}]},{"cell_type":"code","source":["for k in range(best_k2):\n","    print(\"TOPIC\", k)\n","    print(\"distribusi:\")\n","    print([item for item in model.get_topic_word_dist(k,normalize=True)])\n","    print(\"==========================\")\n"],"metadata":{"id":"RfnhfZc9mOoq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get count by super topic\n","model.get_count_by_super_topic()\n","\n","# jumlah kata yang dialokasikan untuk setiap supertopic"],"metadata":{"id":"Taf5TXwpqVAV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688820062633,"user_tz":-420,"elapsed":399,"user":{"displayName":"Tri Rejeki","userId":"03000653045569033643"}},"outputId":"ac18370b-4880-4536-eee8-33c2a0f3efeb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([379247, 388253, 367516], dtype=uint64)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# get count by topics\n","model.get_count_by_topics()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaCy0FbVjeg8","executionInfo":{"status":"ok","timestamp":1688820066371,"user_tz":-420,"elapsed":396,"user":{"displayName":"Tri Rejeki","userId":"03000653045569033643"}},"outputId":"5f9e12d7-d6b5-42ae-e8d6-a1e87641d5c3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([111541,  62432,  64801,  67935,  22603,  29413, 110243,  96304,\n","        43910,  72728,  32703,  43537,  68927,  48347,  95855, 163737],\n","      dtype=uint64)"]},"metadata":{},"execution_count":11}]}]}